{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning and Supervised Learning basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "hnxi9OZKICvd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gradient Training - Basic ML with TensorFlow\n",
        "\n",
        "Below notebook shows basic example for neural network training using TensorFlow. In the excercise below, you'll work on a model that predicts numbers from images. To do so, we will use MNIST database.\n",
        "\n",
        "This notebook is based on [this repository example](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/2_BasicModels/logistic_regression.py).\n",
        "\n",
        "---------------------"
      ]
    },
    {
      "metadata": {
        "id": "vWmELsfWJliy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1. Prepare your environment\n",
        "\n",
        "To run this notebook you need to have:\n",
        " - Tensorflow (either CPU or GPU version),\n",
        " - Numpy,\n",
        " - Matplotlib.\n",
        "\n",
        "**Google Collaborator** did it for us, so we don't have to execute any command and install packages manually."
      ]
    },
    {
      "metadata": {
        "id": "t0Zb5nK04WQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmRUgGi-KASs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2. Prepare dataset\n",
        "\n",
        "In this step we will prepare our MNIST dataset for training.\n",
        "\n",
        "**Don't worry!** Image preprocessing part will be described lated during our course when we will talk more about Computer Vision."
      ]
    },
    {
      "metadata": {
        "id": "XMu_ofjlUojD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below preprocessing makes sure that:\n",
        "  - images are zero-centered and normalized,\n",
        "  - images are flattened to vector of 784 floats (28*28),\n",
        "  - labels are in the one hot format."
      ]
    },
    {
      "metadata": {
        "id": "p536_Gcf4Xpn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Compute mean and std image for normalization\n",
        "mean_image = np.mean(x_train)\n",
        "std_image = np.std(x_train)\n",
        "\n",
        "# Normalize images by subtracting mean image and dividing std image\n",
        "x_train = (x_train - mean_image) / std_image\n",
        "x_test = (x_test - mean_image) / std_image\n",
        "\n",
        "# Change shape of images from 2D image 28x28 to 1D vector 1x784\n",
        "x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28*28)\n",
        "\n",
        "# Convert labels from numbers to one hot vector\n",
        "y_train = tf.Session().run(tf.one_hot(y_train, 10))\n",
        "y_test = tf.Session().run(tf.one_hot(y_test, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wLMyjVXl_juA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert x_train.shape == (60000, 784), 'Invalid training images shape! Please double check your code.'\n",
        "assert y_train.shape == (60000, 10), 'Invalid training labels shape! Please double check your code.'\n",
        "assert x_test.shape == (10000, 784), 'Invalid training images shape! Please double check your code.'\n",
        "assert y_test.shape == (10000, 10), 'Invalid training labels shape! Please double check your code.'\n",
        "assert abs(np.mean(x_train)) <= 1e-2, 'Mean pixel values in train dataset should be close to 0. Current value: {}'.format(np.mean(x_train))\n",
        "assert abs(1.0 - np.std(x_train)) <= 1e-2, 'Standard deviation of pixel values in train dataset should be close to 1. Current value: {}'.format(np.std(x_train))\n",
        "assert abs(np.mean(x_test)) <= 1e-2, 'Mean pixel values in test dataset should be close to 0. Current value: {}'.format(np.mean(x_test))\n",
        "assert abs(1.0 - np.std(x_test)) <= 1e-2, 'Standard deviation of pixel values in test dataset should be close to 1. Current value: {}'.format(np.std(x_test))\n",
        "print('Everything is fine!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yFOJ88DpVLkh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize an example entry in training dataset!\n"
      ]
    },
    {
      "metadata": {
        "id": "QpfUDwL-5p15",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_train[0].reshape(28, 28))\n",
        "plt.show()\n",
        "print('Label as one hot:', y_train[0])\n",
        "print('Label as number:', np.argmax(y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZpzbKSBKJLr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3. Define hyperparameters\n",
        "\n",
        "In machine learning, a **hyperparameter** is a parameter whose value is set before the learning process begins!"
      ]
    },
    {
      "metadata": {
        "id": "wiwHwqGx4ZcU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "training_epochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Bf5jLRIKOCP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4. Prepare your graph - a neural network model\n",
        "\n",
        "For the purpose of this training, you'll prepare a simple one-layer neural network."
      ]
    },
    {
      "metadata": {
        "id": "9rA5zHLeK7gS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below you can find a representation of our single neural network layer as a TensorFlow graph:\n",
        "\n",
        "![Simple model graph](https://i.imgur.com/N8MproZ.png)"
      ]
    },
    {
      "metadata": {
        "id": "y_705AgyWv3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below, you need to define:\n",
        "  - `x` placeholder for network input,\n",
        "  - `W` variable for weight tensor initialized with normal distribution,\n",
        "  - `b` variable for bias tensor initialized with zeros,\n",
        "  - `model` which defines computation graph."
      ]
    },
    {
      "metadata": {
        "id": "_zXKKz7n4zY7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Inputs\n",
        "x = ...\n",
        "\n",
        "# Set model weights\n",
        "W = ...\n",
        "b = ...\n",
        "\n",
        "# Construct model\n",
        "model = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBPkPlOTO4gm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert x.shape[1] == 784, 'Your neural network needs to get an input of 784 values (flatten image 28x28).'\n",
        "assert W.shape[0] == 784, 'Your weight Tensor\\'s first dimension should equal to 784.'\n",
        "assert W.shape[1] == 10, 'Your weight Tensor\\'s second dimension should equal to 10.'\n",
        "assert b.shape[0] == 10, 'Your bias Tensor\\'s dimension should equal to 10.'\n",
        "print('Everything is fine!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WqcsVtJXmb_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5. Prepare your optimizer\n",
        "\n",
        "Our model is ready for training. But before we do so, we need to prepare a loss function and SGD optimizer. Also, you will need to prepare an initializer for all variables. After that, we need to have a Session object for computations during this excercise."
      ]
    },
    {
      "metadata": {
        "id": "qTQC6ba6L_cp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below you can find a representation of our loss function as a TensorFlow graph:\n",
        "\n",
        "![Graph for loss function](https://i.imgur.com/Echiwjp.png)"
      ]
    },
    {
      "metadata": {
        "id": "8CbegKzbYp1V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below, you need to define:\n",
        "  - `y` placeholder for output label (needed to compute loss),\n",
        "  - `loss` which defines computation graph,\n",
        "  - `optimizer` which should be SGD (tf.train.GradientDescentOptimizer)."
      ]
    },
    {
      "metadata": {
        "id": "Na00sZ2m5Gcj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Minimize error using cross entropy\n",
        "y = ...\n",
        "loss = ...\n",
        "\n",
        "# Gradient Descent\n",
        "optimizer = ...\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Prepare global TF Session object\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGl2Rm95Q5Gv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert 'GradientDescent' in optimizer.name, 'Change your optimizer to SGD!'\n",
        "assert y.shape[1] == 10, 'Your neural network needs to output 10 values (possible 10 classes).'\n",
        "print('Everything is fine!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zJt13cuKWRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 6. Let's start the training!\n",
        "\n",
        "It's high time to train our model!"
      ]
    },
    {
      "metadata": {
        "id": "uRpQRCeIYTBk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What you need to do is:\n",
        "  - initialize your variables,\n",
        "  - pass whole training dataset multiple times,\n",
        "  - pass whole test dataset to know how well our model works."
      ]
    },
    {
      "metadata": {
        "id": "MtQTsfIV1m0a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run the initializer\n",
        "...\n",
        "\n",
        "# Training cycle\n",
        "for epoch in range(training_epochs):\n",
        "  # Pass whole training dataset through our model\n",
        "  _, total_loss = sess.run([...], feed_dict={\n",
        "    x: ...,\n",
        "    y: ...,\n",
        "  })\n",
        "\n",
        "  # Display logs per epoch step\n",
        "  print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \"{:.9f}\".format(total_loss))\n",
        "\n",
        "print('Training Finished!')\n",
        "\n",
        "# Test model\n",
        "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy:\", sess.run(accuracy, {x: x_test, y: y_test}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7xXWbbWZqMZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize our network prediction on example test image."
      ]
    },
    {
      "metadata": {
        "id": "v_Jr5uP7LG72",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_test[0].reshape(28, 28))\n",
        "plt.show()\n",
        "\n",
        "model_input = np.expand_dims(x_test[0], 0)  # Add batch dimension!\n",
        "model_output = sess.run(model, {x: model_input})\n",
        "print('Model responded:', model_output[0])\n",
        "print('It is:', np.argmax(model_output[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVO8fJETKZqO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 7. Batch training\n",
        "\n",
        "Instead of passing whole dataset at once, it is better to train our model with batches (or even minibatches)."
      ]
    },
    {
      "metadata": {
        "id": "YTGbImlEaCcb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What you need to do is:\n",
        "  - initialize your variables,\n",
        "  - pass whole training dataset multiple times but this time in multiple smaller parts (named \"batches\"),\n",
        "  - pass whole test dataset to know how well our model works (you can also pass them with minibatches)."
      ]
    },
    {
      "metadata": {
        "id": "CI6L580d1oIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define new hyperparameter and tweak learning rate\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Run the initializer\n",
        "sess.run(init)\n",
        "\n",
        "# Training cycle\n",
        "number_of_batches = int(x_train.shape[0] / batch_size)\n",
        "for epoch in range(training_epochs):\n",
        "  total_loss = 0.0\n",
        "\n",
        "  # Loop over all batches\n",
        "  for i in range(number_of_batches):\n",
        "    batch_xs = x_train[...:...]\n",
        "    batch_ys = y_train[...:...]\n",
        "    _, batch_loss = sess.run([...], feed_dict={\n",
        "        x: batch_xs,\n",
        "        y: batch_ys,\n",
        "    })\n",
        "    total_loss += batch_loss\n",
        "\n",
        "  # Display logs per epoch step\n",
        "  mean_loss = total_loss / number_of_batches\n",
        "  print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \"{:.9f}\".format(mean_loss))\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "# Test model\n",
        "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy:\", sess.run(accuracy, {x: x_test, y: y_test}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xlETqoWajHk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize our network prediction on example test image."
      ]
    },
    {
      "metadata": {
        "id": "Ze6USIazHB8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_test[0].reshape(28, 28))\n",
        "plt.show()\n",
        "\n",
        "model_input = np.expand_dims(x_test[0], 0)  # Add batch dimension!\n",
        "model_output = sess.run(model, {x: model_input})\n",
        "print('Model responded:', model_output[0])\n",
        "print('It is:', np.argmax(model_output[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIoAADMWalj1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "That's all! I hope that you've learn something useful today :)\n",
        "\n",
        "**Your homework:**\n",
        "  - experiment with different learning rate & batch size,\n",
        "  - check what will happen if you change the way you initialize layers,\n",
        "  - extend your model and add another fully-connected layer,\n",
        "  - split training dataset into training dataset and validation dataset to prevent overfitting.\n",
        "\n",
        "**Where to get more information?**\n",
        "  - Great introduction & visualization of Neural Networks by [3Blue1Brown on YouTube](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi),\n",
        "  - TensorFlow in 5 minutes by [Siraj Raval on YouTube](https://www.youtube.com/watch?v=2FmcHiLCwTU),\n",
        "  - Short videos about Neural Networks by [Welch Labs on YouTube](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU),\n",
        "  - Part I: Applied Math and Machine Learning Basics of [Deep Learning Book](http://www.deeplearningbook.org),\n",
        "  - A Visual and Interactive Guide to the Basics of Neural Networks by Jay Alammar's ([Blog post](http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)),\n",
        "  - [CS229 Course](http://cs229.stanford.edu) from Stanford (lectures can be found on YouTube),\n",
        "  - [CS231n Course](http://cs231n.stanford.edu) from Stanford (lectures can be found on YouTube)."
      ]
    }
  ]
}
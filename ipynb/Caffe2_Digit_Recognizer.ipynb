{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer in Caffe2\n",
    "This is an example of Digit Recognizer implementation written in Caffe2. It mostly bases on Caffe2 examples stored on their [website](https://caffe2.ai/docs/tutorial-MNIST.html).\n",
    "\n",
    "I've earned 0.98314, which I think is cool for a simple LeNet :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython import display\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import cnn, core, utils, workspace, net_drawer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "At the beginning we've got to load CSV files from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('/MNIST/data/train.csv')\n",
    "test_csv = pd.read_csv('/MNIST/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we've got to read all of the data stored in these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fetch data from CSV files\n",
    "X_train = train_csv.ix[:,1:].values.astype('float32')\n",
    "y_train = train_csv.ix[:,0].values.astype('int32')\n",
    "X_test = test_csv.values.astype('float32')\n",
    "\n",
    "# Reshape all images (1x784 -> 28x28)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28)\n",
    "\n",
    "# Add feature layer\n",
    "X_train = np.expand_dims(X_train, axis=1)\n",
    "X_test = np.expand_dims(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw files need to be preprocessed and split into training and validation set which we do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature standardization\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "standardize = lambda image: (image - mean_px) / std_px\n",
    "\n",
    "# Preprocessing\n",
    "X_train = np.array([standardize(image) for image in X_train])\n",
    "X_test = np.array([standardize(image) for image in X_test])\n",
    "\n",
    "# Split all dataset for training and validation set\n",
    "X_validation = np.array(X_train[:1000])\n",
    "y_validation = np.array(y_train[:1000])\n",
    "X_train = np.array(X_train[1000:])\n",
    "y_train = np.array(y_train[1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare databases\n",
    "Caffe2 uses its databases to store and fetch data. Below function creates a single levelDB database and will it with data from NumPy arrays that we've prepared above. Note that you can create database with only input images (labels will be filled with -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Caffe2 database for out MNIST data\n",
    "def create_database(db_name, images, labels=None):\n",
    "    # Create empty leveldb database\n",
    "    db = core.C.create_db('leveldb', db_name, core.C.Mode.write)\n",
    "    transaction = db.new_transaction()\n",
    "    \n",
    "    # Move all data to the database\n",
    "    for i in range(images.shape[0]):\n",
    "        tensor_protos = caffe2_pb2.TensorProtos()\n",
    "        \n",
    "        # Copy image with MNIST number\n",
    "        img_tensor = tensor_protos.protos.add()\n",
    "        img_tensor.dims.extend(images[i].shape)\n",
    "        img_tensor.data_type = 1\n",
    "        flatten_img = images[i].reshape(np.prod(images[i].shape))\n",
    "        img_tensor.float_data.extend(flatten_img)\n",
    "\n",
    "        # Copy label for each number\n",
    "        label_tensor = tensor_protos.protos.add()\n",
    "        label_tensor.data_type = 2\n",
    "        if labels is not None:\n",
    "            label_tensor.int32_data.append(labels[i])\n",
    "        else:\n",
    "            label_tensor.int32_data.append(-1)\n",
    "\n",
    "        # Add data in transaction\n",
    "        transaction.put('%0.6d' % i, tensor_protos.SerializeToString())\n",
    "\n",
    "    # Close the transaction and close the database\n",
    "    del transaction\n",
    "    del db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've got to create all databases (train, validation and test) using our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create all databases\n",
    "create_database('db_train', X_train, y_train)\n",
    "create_database('db_validation', X_validation, y_validation)\n",
    "create_database('db_test', X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create models\n",
    "Once we've got out data ready to train, validate and predict, we need to prepare our model. Let's write a simple method that will create LeNet neural network with appropriate operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(model_name, db_name, batch_size=100, train=True, accuracy=True):\n",
    "    # Create empty model with CCN model helper (and initialize if needed for training)\n",
    "    if train:\n",
    "        model = cnn.CNNModelHelper(order=\"NCHW\", name=model_name)\n",
    "    else:\n",
    "        model = cnn.CNNModelHelper(order=\"NCHW\", name=model_name, init_params=False)\n",
    "\n",
    "    # Prepare data input operator that will fetch data from DB\n",
    "    data, label = model.TensorProtosDBInput([], ['data', 'label'], batch_size=batch_size, db=db_name, db_type='leveldb')\n",
    "    data = model.StopGradient(data, data)\n",
    "    \n",
    "    # First convolution: 28 x 28 -> 24 x 24\n",
    "    conv1 = model.Conv(data, 'conv1', dim_in=1, dim_out=20, kernel=5)\n",
    "    \n",
    "    # First pooling: 24 x 24 -> 12 x 12\n",
    "    pool1 = model.MaxPool(conv1, 'pool1', kernel=2, stride=2)\n",
    "    \n",
    "    # Second convolution: 12 x 12 -> 8 x 8\n",
    "    conv2 = model.Conv(pool1, 'conv2', dim_in=20, dim_out=50, kernel=5)\n",
    "    \n",
    "    # Second pooling: 8 x 8 -> 4 x 4\n",
    "    pool2 = model.MaxPool(conv2, 'pool2', kernel=2, stride=2)\n",
    "    \n",
    "    # Fully connected layers at the end\n",
    "    fc3 = model.FC(pool2, 'fc3', dim_in=50 * 4 * 4, dim_out=500) # 50 * 4 * 4 = dim_out from previous layer * image size\n",
    "    fc3 = model.Relu(fc3, fc3)\n",
    "    pred = model.FC(fc3, 'pred', 500, 10)\n",
    "    softmax = model.Softmax(pred, 'softmax')\n",
    "    \n",
    "    # Check if we need to add training operators\n",
    "    if train:\n",
    "        # Prepare Cross Entropy operators with loss\n",
    "        xent = model.LabelCrossEntropy([softmax, label], 'xent')\n",
    "        loss = model.AveragedLoss(xent, \"loss\")\n",
    "\n",
    "        # Add all gradient operators that will be needed to calculate our loss and train our model\n",
    "        model.AddGradientOperators([loss])\n",
    "        \n",
    "        # Prepare variables for SGD\n",
    "        ITER = model.Iter(\"iter\")\n",
    "        LR = model.LearningRate(ITER, \"LR\", base_lr=-0.1, policy=\"step\", stepsize=1, gamma=0.999)\n",
    "        ONE = model.param_init_net.ConstantFill([], \"ONE\", shape=[1], value=1.0)\n",
    "        \n",
    "        # Update all gradients for each params\n",
    "        for param in model.params:\n",
    "            # Note how we get the gradient of each parameter - CNNModelHelper keeps\n",
    "            # track of that\n",
    "            param_grad = model.param_to_grad[param]\n",
    "            \n",
    "            # The update is a simple weighted sum: param = param + param_grad * LR\n",
    "            model.WeightedSum([param, ONE, param_grad, LR], param)\n",
    "    \n",
    "    # Add accuracy metrics if needed\n",
    "    if accuracy:\n",
    "        model.Accuracy([softmax, label], \"accuracy\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function is ready to use! Let's prepare our networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create all needed models\n",
    "training_model = create_model('mnist_train', 'db_train')\n",
    "validation_model = create_model('mnist_validation', 'db_validation', train=False)\n",
    "test_model = create_model('mnist_test', 'db_test', train=False, accuracy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & validation\n",
    "Let's prepare a function that will validate our model and return average accuracy for validation dataset. We'll use it in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_validation_accuracy():\n",
    "    # Initialize our model\n",
    "    workspace.RunNetOnce(validation_model.param_init_net)\n",
    "    workspace.CreateNet(validation_model.net)\n",
    "    \n",
    "    # Iterate over all validation dataset\n",
    "    all_accuracy = []\n",
    "    for i in range(X_validation.shape[0]/100):\n",
    "        workspace.RunNet(validation_model.net.Proto().name)\n",
    "        all_accuracy.append(workspace.FetchBlob('accuracy'))\n",
    "    \n",
    "    # Return mean accuracy for validation dataset\n",
    "    return np.array(all_accuracy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the main part of the whole kernel. Let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20/1000 TIME_per_epoch: 0.710s TRAIN_Loss: 0.8379 TRAIN_Acc: 0.7100 VAL_Acc: 0.8110\n",
      "Epoch #40/1000 TIME_per_epoch: 0.744s TRAIN_Loss: 0.3694 TRAIN_Acc: 0.8800 VAL_Acc: 0.8570\n",
      "Epoch #60/1000 TIME_per_epoch: 0.654s TRAIN_Loss: 0.3639 TRAIN_Acc: 0.8600 VAL_Acc: 0.8850\n",
      "Epoch #80/1000 TIME_per_epoch: 0.643s TRAIN_Loss: 0.1741 TRAIN_Acc: 0.9300 VAL_Acc: 0.9390\n",
      "Epoch #100/1000 TIME_per_epoch: 0.726s TRAIN_Loss: 0.3538 TRAIN_Acc: 0.8700 VAL_Acc: 0.8700\n",
      "Epoch #120/1000 TIME_per_epoch: 0.771s TRAIN_Loss: 0.2968 TRAIN_Acc: 0.8900 VAL_Acc: 0.9250\n",
      "Epoch #140/1000 TIME_per_epoch: 0.710s TRAIN_Loss: 0.1340 TRAIN_Acc: 0.9600 VAL_Acc: 0.9610\n",
      "Epoch #160/1000 TIME_per_epoch: 0.629s TRAIN_Loss: 0.1515 TRAIN_Acc: 0.9500 VAL_Acc: 0.9550\n",
      "Epoch #180/1000 TIME_per_epoch: 0.597s TRAIN_Loss: 0.1361 TRAIN_Acc: 0.9700 VAL_Acc: 0.9640\n",
      "Epoch #200/1000 TIME_per_epoch: 0.924s TRAIN_Loss: 0.2472 TRAIN_Acc: 0.9400 VAL_Acc: 0.9600\n",
      "Epoch #220/1000 TIME_per_epoch: 0.646s TRAIN_Loss: 0.1090 TRAIN_Acc: 0.9800 VAL_Acc: 0.9710\n",
      "Epoch #240/1000 TIME_per_epoch: 0.806s TRAIN_Loss: 0.0864 TRAIN_Acc: 0.9700 VAL_Acc: 0.9740\n",
      "Epoch #260/1000 TIME_per_epoch: 0.709s TRAIN_Loss: 0.0603 TRAIN_Acc: 0.9800 VAL_Acc: 0.9670\n",
      "Epoch #280/1000 TIME_per_epoch: 0.748s TRAIN_Loss: 0.0397 TRAIN_Acc: 0.9900 VAL_Acc: 0.9730\n",
      "Epoch #300/1000 TIME_per_epoch: 1.095s TRAIN_Loss: 0.0807 TRAIN_Acc: 0.9700 VAL_Acc: 0.9770\n",
      "Epoch #320/1000 TIME_per_epoch: 0.649s TRAIN_Loss: 0.0471 TRAIN_Acc: 0.9800 VAL_Acc: 0.9800\n",
      "Epoch #340/1000 TIME_per_epoch: 0.665s TRAIN_Loss: 0.0672 TRAIN_Acc: 0.9700 VAL_Acc: 0.9770\n",
      "Epoch #360/1000 TIME_per_epoch: 0.822s TRAIN_Loss: 0.1071 TRAIN_Acc: 0.9700 VAL_Acc: 0.9780\n",
      "Epoch #380/1000 TIME_per_epoch: 0.671s TRAIN_Loss: 0.0857 TRAIN_Acc: 0.9600 VAL_Acc: 0.9800\n",
      "Epoch #400/1000 TIME_per_epoch: 2.078s TRAIN_Loss: 0.0804 TRAIN_Acc: 0.9800 VAL_Acc: 0.9730\n",
      "Epoch #420/1000 TIME_per_epoch: 0.776s TRAIN_Loss: 0.0284 TRAIN_Acc: 0.9900 VAL_Acc: 0.9790\n",
      "Epoch #440/1000 TIME_per_epoch: 0.761s TRAIN_Loss: 0.0899 TRAIN_Acc: 0.9700 VAL_Acc: 0.9930\n",
      "Epoch #460/1000 TIME_per_epoch: 0.936s TRAIN_Loss: 0.0756 TRAIN_Acc: 0.9800 VAL_Acc: 0.9850\n",
      "Epoch #480/1000 TIME_per_epoch: 0.631s TRAIN_Loss: 0.0361 TRAIN_Acc: 0.9900 VAL_Acc: 0.9860\n",
      "Epoch #500/1000 TIME_per_epoch: 0.645s TRAIN_Loss: 0.0364 TRAIN_Acc: 0.9900 VAL_Acc: 0.9830\n",
      "Epoch #520/1000 TIME_per_epoch: 0.627s TRAIN_Loss: 0.0659 TRAIN_Acc: 0.9800 VAL_Acc: 0.9880\n",
      "Epoch #540/1000 TIME_per_epoch: 0.650s TRAIN_Loss: 0.0317 TRAIN_Acc: 1.0000 VAL_Acc: 0.9950\n",
      "Epoch #560/1000 TIME_per_epoch: 0.607s TRAIN_Loss: 0.0543 TRAIN_Acc: 0.9800 VAL_Acc: 0.9930\n",
      "Epoch #580/1000 TIME_per_epoch: 0.715s TRAIN_Loss: 0.0580 TRAIN_Acc: 0.9900 VAL_Acc: 0.9950\n",
      "Epoch #600/1000 TIME_per_epoch: 0.903s TRAIN_Loss: 0.0181 TRAIN_Acc: 1.0000 VAL_Acc: 0.9940\n",
      "Epoch #620/1000 TIME_per_epoch: 0.637s TRAIN_Loss: 0.0353 TRAIN_Acc: 0.9800 VAL_Acc: 0.9960\n",
      "Epoch #640/1000 TIME_per_epoch: 1.023s TRAIN_Loss: 0.0431 TRAIN_Acc: 0.9900 VAL_Acc: 0.9960\n"
     ]
    }
   ],
   "source": [
    "# Initialize out training model\n",
    "workspace.RunNetOnce(training_model.param_init_net)\n",
    "workspace.CreateNet(training_model.net)\n",
    "\n",
    "# Iterate over all epochs\n",
    "NUMBER_OF_EPOCHS = 1000\n",
    "for i in range(NUMBER_OF_EPOCHS):\n",
    "    # Train our model\n",
    "    start_time = time.time()\n",
    "    workspace.RunNet(training_model.net.Proto().name)\n",
    "    \n",
    "    # Once per 20 epochs let's run validation and print results\n",
    "    if (i+1) % 20 == 0:\n",
    "        train_loss = workspace.FetchBlob('loss')\n",
    "        train_accuracy = workspace.FetchBlob('accuracy')\n",
    "        val_accuracy = calculate_validation_accuracy()\n",
    "        epoch_time = time.time()-start_time\n",
    "        print(('Epoch #%d/%d TIME_per_epoch: %.3fs '+\n",
    "               'TRAIN_Loss: %.4f TRAIN_Acc: %.4f '+\n",
    "               'VAL_Acc: %.4f') % (i+1, NUMBER_OF_EPOCHS, epoch_time, train_loss, train_accuracy, val_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Our model is ready to use and now we can use it to predict all test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting #20/280...\n",
      "Predicting #40/280...\n",
      "Predicting #60/280...\n",
      "Predicting #80/280...\n",
      "Predicting #100/280...\n",
      "Predicting #120/280...\n",
      "Predicting #140/280...\n",
      "Predicting #160/280...\n",
      "Predicting #180/280...\n",
      "Predicting #200/280...\n",
      "Predicting #220/280...\n",
      "Predicting #240/280...\n",
      "Predicting #260/280...\n",
      "Predicting #280/280...\n"
     ]
    }
   ],
   "source": [
    "# Initialize out prediction model\n",
    "workspace.RunNetOnce(test_model.param_init_net)\n",
    "workspace.CreateNet(test_model.net)\n",
    "\n",
    "# Iterate over all test dataset\n",
    "predicted_labels = []\n",
    "for i in range(X_test.shape[0]/100):\n",
    "    # Run our model for predicting labels\n",
    "    workspace.RunNet(test_model.net.Proto().name)\n",
    "    batch_prediction = workspace.FetchBlob('softmax')\n",
    "    if (i+1) % 20 == 0:\n",
    "        print('Predicting #{}/{}...'.format(i+1, X_test.shape[0]/100))\n",
    "    \n",
    "    # Retrieve labels\n",
    "    for prediction in batch_prediction:\n",
    "        predicted_labels.append(np.argmax(prediction))  # Label = index of max argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle submission\n",
    "Our predicted labels should be stored in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved on disk!\n"
     ]
    }
   ],
   "source": [
    "# Save all predicted labels into CSV file\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": list(range(1, len(predicted_labels)+1)),\n",
    "    \"Label\": predicted_labels\n",
    "})\n",
    "submission.to_csv('/MNIST/data/output.csv', index=False, header=True)\n",
    "print('Saved on disk!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The END\n",
    "That's all! I hope that will be helpful for all of the people starting with Caffe2 on Kaggle :)  \n",
    "\n",
    "I'm waiting for your comments and ideas for improving this Kernel!  \n",
    "Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
